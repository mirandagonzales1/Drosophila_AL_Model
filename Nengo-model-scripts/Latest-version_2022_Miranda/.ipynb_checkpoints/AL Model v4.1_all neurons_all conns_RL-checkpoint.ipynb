{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import Odorant_Stim_8odors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "\n",
    "def read_connections(filename):\n",
    "            #r = list(csv.reader(open('updated_erecta_all_circuitry_absolute.csv'))) #Need to get updated connectivity from Ruairi with all neurons\n",
    "            #r = list(csv.reader(open('updated_melanogaster_all_circuitry_absolute.csv'))) #does this need to be changed to 'filename'?\n",
    "    r = list(csv.reader(open(filename)))\n",
    "        \n",
    "    header = r[0]\n",
    "    data = r[1:]\n",
    "\n",
    "    conns = {}\n",
    "    for row in data:\n",
    "        for i, item in enumerate(row):\n",
    "            if i > 0:\n",
    "                pre = row[0]\n",
    "                post = header[i]\n",
    "                c = int(item)\n",
    "                if c > 0:\n",
    "                    if pre not in conns:\n",
    "                        conns[pre] = {}\n",
    "                    conns[pre][post] = c\n",
    "                    \n",
    "    ORNs_left = [name for name in header if 'ORN' in name and 'left' in name]\n",
    "    ORNs_right = [name for name in header if 'ORN' in name and 'right' in name]\n",
    "    uPNs_left = [name for name in header if ' uPN' in name and 'left' in name]\n",
    "    uPNs_right = [name for name in header if ' uPN' in name and 'right' in name]\n",
    "    mPNs_left = [name for name in header if 'mPN' in name and 'left' in name]\n",
    "    mPNs_right = [name for name in header if 'mPN' in name and 'right' in name]\n",
    "    Pickys_left = [name for name in header if 'icky' in name and 'left' in name]\n",
    "    Pickys_right = [name for name in header if 'icky' in name and 'right' in name]\n",
    "    Choosys_left = [name for name in header if 'hoosy' in name and 'left' in name]\n",
    "    Choosys_right = [name for name in header if 'hoosy' in name and 'right' in name]\n",
    "    Broads_left = [name for name in header if 'road' in name and 'left' in name]\n",
    "    Broads_right = [name for name in header if 'road' in name and 'right' in name]\n",
    "    Keystone_left = [name for name in header if 'eystone' in name and 'left' in name]\n",
    "    Keystone_right = [name for name in header if 'eystone' in name and 'right' in name]\n",
    "    Ventral_left = [name for name in header if 'entral' in name and 'left' in name]\n",
    "    Ventral_right = [name for name in header if 'entral' in name and 'right' in name]\n",
    "\n",
    "        \n",
    "    Names = collections.namedtuple('Names', ['ORNs_left', 'uPNs_left', 'mPNs_left', 'Pickys_left',\n",
    "                                                  'Choosys_left','Broads_left','Keystone_left','Ventral_left',\n",
    "                                            'ORNs_right', 'uPNs_right', 'mPNs_right', 'Pickys_right',\n",
    "                                                  'Choosys_right','Broads_right','Keystone_right','Ventral_right'])\n",
    "    \n",
    "    \n",
    "    return conns, Names(ORNs_left, uPNs_left, mPNs_left, Pickys_left,\n",
    "                             Choosys_left,Broads_left,Keystone_left,Ventral_left,\n",
    "                             ORNs_right, uPNs_right, mPNs_right, Pickys_right,\n",
    "                             Choosys_right,Broads_right,Keystone_right,Ventral_right)\n",
    "\n",
    "\n",
    "def make_weights(conns, pre, post):\n",
    "    w = np.zeros((len(post), len(pre))) #note: pre/post switched in output array for print(make_weights())\n",
    "    for i, pre_n in enumerate(pre):\n",
    "        if pre_n not in conns:\n",
    "                continue\n",
    "        for j, post_n in enumerate(post):\n",
    "            if post_n in conns[pre_n]:\n",
    "                w[j,i] = conns[pre_n][post_n] \n",
    "            else:\n",
    "                continue\n",
    "    return w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "\n",
    "def compute_rate_to_current(neuron_model=nengo.LIFRate(), max_current=10.0):\n",
    "    tuning_model = nengo.Network()\n",
    "    with tuning_model:\n",
    "        N = 1\n",
    "        T = 10\n",
    "        max_current = 10.0\n",
    "        n = nengo.Ensemble(n_neurons=N, dimensions=1,\n",
    "                           neuron_type=nengo.LIFRate(),\n",
    "                           gain=[1]*N, bias=[0]*N,\n",
    "                           )\n",
    "\n",
    "        stim = nengo.Node(lambda t: t/T*max_current)\n",
    "        nengo.Connection(stim, n.neurons, transform=np.ones((N, 1)), synapse=None)\n",
    "        p_rate = nengo.Probe(n.neurons)\n",
    "        p_current = nengo.Probe(stim)\n",
    "    sim = nengo.Simulator(tuning_model, progress_bar=False)\n",
    "    with sim:\n",
    "        sim.run(T)\n",
    "    rate_to_current = scipy.interpolate.interp1d(sim.data[p_rate][:,0], sim.data[p_current][:,0])\n",
    "    return rate_to_current\n",
    "\n",
    "\n",
    "rate_to_current = compute_rate_to_current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytry\n",
    "import seaborn as sns\n",
    "\n",
    "class PickyTrial_AL(pytry.PlotTrial):\n",
    "    def params(self):\n",
    "        self.param('species (melanogaster|erecta)', species='melanogaster')\n",
    "        self.param('hemisphere (right|left|averaged)', hemisphere='left')\n",
    "        self.param('background OR rate', background_rate_OR=6.0)\n",
    "        self.param('concentration of odorant (log scale)', concentration=-4)\n",
    "        self.param('odorant (geranyl acetate|anisole|2-heptanone|menthol|methyl salicylate|benzaldehyde|acetal|methyl phenyl sulfide|)', odorant='2-heptanone')\n",
    "        \n",
    "             \n",
    "        groups = ['uPN', 'mPN','Picky','Broad', 'Choosy', 'Ventral', 'Keystone', 'ORN']\n",
    "        \n",
    "        inhibitory = ['Picky','Broad', 'Choosy', 'Ventral', 'Keystone']\n",
    "            \n",
    "        for start in groups:\n",
    "            for end in groups:\n",
    "                \n",
    "                variable = f'w_{start}_{end}'\n",
    "                if start in inhibitory:\n",
    "                    value = -0.001\n",
    "                elif end in inhibitory:\n",
    "                    value = 0.0001533\n",
    "                else:\n",
    "                    value = 0.0005\n",
    "                arguments = {}\n",
    "                arguments[variable] = value\n",
    "                \n",
    "                self.param(f'synapse strength for {start} to {end}', **arguments) \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def evaluate(self, p, plt):\n",
    "        \n",
    "        conns, names = read_connections('updated_'+p.species+'_all_circuitry_absolute.csv')\n",
    "        model = nengo.Network(seed=p.seed)\n",
    "        with model:\n",
    "            \n",
    "            stims = [-20,-20,-20,p.concentration,p.concentration,p.concentration,-20]\n",
    "            log_concentrations = nengo.Node(nengo.processes.PresentInput(stims, presentation_time=1))\n",
    "\n",
    "            def logconc_to_conc_func(t, x):              \n",
    "                return 10**x     \n",
    "            concentrations = nengo.Node(logconc_to_conc_func, size_in=1)\n",
    "            odorant_index = ['geranyl acetate', 'anisole', '2-heptanone', 'menthol',\n",
    "                            'methyl salicylate', 'benzaldehyde', 'acetal', 'methyl phenyl sulfide'].index(p.odorant)\n",
    "            \n",
    "            def OR_func(t, x):\n",
    "                rel = Odorant_Stim_8odors.convert_compounds_to_responses(x)\n",
    "                max_rate_range = [80,50,50,80,38,46,31,40]\n",
    "                max_rate = max_rate_range[odorant_index]\n",
    "                background_rate = p.background_rate_OR\n",
    "                return rate_to_current(rel*max_rate+background_rate)\n",
    "            \n",
    "            if p.hemisphere=='left':\n",
    "                names_ORN = names.ORNs_left\n",
    "                names_uPN = names.uPNs_left\n",
    "                names_mPN = names.mPNs_left\n",
    "                names_Picky = names.Pickys_left\n",
    "                names_Broad = names.Broads_left\n",
    "                names_Choosy = names.Choosys_left\n",
    "                names_Ventral = names.Ventral_left\n",
    "                names_Keystone = names.Keystone_left\n",
    "                \n",
    "            elif p.hemisphere=='right':\n",
    "                names_ORN = names.ORNs_right\n",
    "                names_uPN = names.uPNs_right\n",
    "                names_mPN = names.mPNs_right\n",
    "                names_Picky = names.Pickys_right\n",
    "                names_Broad = names.Broads_right\n",
    "                names_Choosy = names.Choosys_right\n",
    "                names_Ventral = names.Ventral_right\n",
    "                names_Keystone = names.Keystone_right\n",
    "                \n",
    "            elif p.hemisphere=='averaged':\n",
    "                names_ORN_L = names.ORNs_left\n",
    "                names_uPN_L = names.uPNs_left\n",
    "                names_mPN_L = names.mPNs_left\n",
    "                names_Picky_L = names.Pickys_left\n",
    "                names_Broad_L = names.Broads_left\n",
    "                names_Choosy_L = names.Choosys_left\n",
    "                names_Ventral_L = names.Ventral_left\n",
    "                names_Keystone_L = names.Keystone_left\n",
    "                names_ORN_R = names.ORNs_right\n",
    "                names_uPN_R = names.uPNs_right\n",
    "                names_mPN_R = names.mPNs_right\n",
    "                names_Picky_R = names.Pickys_right\n",
    "                names_Broad_R = names.Broads_right\n",
    "                names_Choosy_R = names.Choosys_right\n",
    "                names_Ventral_R = names.Ventral_right\n",
    "                names_Keystone_R = names.Keystone_right\n",
    "                \n",
    "            else:\n",
    "                return 'error: check hemisphere notation'\n",
    "\n",
    "            ORN_current = nengo.Node(OR_func, size_in=8)\n",
    "            ORN = nengo.Ensemble(n_neurons=len(names_ORN), dimensions=1,\n",
    "                                   neuron_type=nengo.LIF(),\n",
    "                                   noise=nengo.processes.WhiteNoise(nengo.dists.Gaussian(0,0.02)),\n",
    "                                   gain=[1]*len(names_ORN), bias=[0]*len(names_ORN))\n",
    "            \n",
    "            nengo.Connection(ORN_current, ORN.neurons, synapse=None)\n",
    "            nengo.Connection(log_concentrations, concentrations, synapse=None)\n",
    "            nengo.Connection(concentrations, ORN_current[odorant_index], synapse=None)\n",
    "\n",
    "            \n",
    "            uPN = nengo.Ensemble(n_neurons=len(names_uPN), dimensions=1,\n",
    "                                   gain=np.ones(len(names_uPN)), bias=np.zeros(len(names_uPN)))\n",
    "            mPN = nengo.Ensemble(n_neurons=len(names_mPN), dimensions=1,\n",
    "                                   gain=np.ones(len(names_mPN)), bias=np.zeros(len(names_mPN)))\n",
    "            Picky = nengo.Ensemble(n_neurons=len(names_Picky), dimensions=1,\n",
    "                                   gain=np.ones(len(names_Picky)), bias=np.zeros(len(names_Picky)))\n",
    "            \n",
    "            Broad = nengo.Ensemble(n_neurons=len(names_Broad), dimensions=1,\n",
    "                                   gain=np.ones(len(names_Broad)), bias=np.zeros(len(names_Broad)))\n",
    "            Choosy = nengo.Ensemble(n_neurons=len(names_Choosy), dimensions=1,\n",
    "                                   gain=np.ones(len(names_Choosy)), bias=np.zeros(len(names_Choosy)))\n",
    "            Ventral = nengo.Ensemble(n_neurons=len(names_Ventral), dimensions=1,\n",
    "                                   gain=np.ones(len(names_Ventral)), bias=np.zeros(len(names_Ventral)))\n",
    "            Keystone = nengo.Ensemble(n_neurons=len(names_Keystone), dimensions=1,\n",
    "                                   gain=np.ones(len(names_Keystone)), bias=np.zeros(len(names_Keystone)))\n",
    "            \n",
    "\n",
    "            groups = ['uPN', 'mPN','Picky','Broad', 'Choosy', 'Ventral', 'Keystone', 'ORN']\n",
    "\n",
    "            \n",
    "            for start in groups:\n",
    "                for end in groups:\n",
    "                    nengo.Connection(locals()[start].neurons, locals()[end].neurons, \n",
    "                                     transform=getattr(p, f'w_{start}_{end}')*make_weights(conns, locals()[f'names_{start}'], locals()[f'names_{end}']), \n",
    "                                     synapse=0.01)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            p_Picky = nengo.Probe(Picky.neurons)\n",
    "            p_uPN = nengo.Probe(uPN.neurons)\n",
    "            p_mPN = nengo.Probe(mPN.neurons)\n",
    "            p_ORN = nengo.Probe(ORN.neurons)\n",
    "            p_Broad = nengo.Probe(Broad.neurons)\n",
    "            p_Choosy = nengo.Probe(Choosy.neurons)\n",
    "            p_Ventral = nengo.Probe(Ventral.neurons)\n",
    "            p_Keystone = nengo.Probe(Keystone.neurons)\n",
    "\n",
    "        sim = nengo.Simulator(model, seed=p.seed+1)\n",
    "        sim.run(7)\n",
    "        \n",
    "        data_ORN = sim.data[p_ORN]\n",
    "        data_uPN = sim.data[p_uPN]\n",
    "        data_mPN = sim.data[p_mPN]\n",
    "        data_Picky = sim.data[p_Picky]\n",
    "        data_Broad = sim.data[p_Broad]\n",
    "        data_Choosy = sim.data[p_Choosy]\n",
    "        data_Ventral = sim.data[p_Ventral]\n",
    "        data_Keystone = sim.data[p_Keystone]\n",
    "        \n",
    "        def calc_max_min_baseline(data_neurons):\n",
    "            filt = nengo.synapses.Lowpass(0.3)\n",
    "                #Change (value) to get diff filters, try 0.1 for rougher data, try 0.01 for what looks like ephys data (ie close to no filter)\n",
    "            filt_data = filt.filtfilt(data_neurons)\n",
    "                #stores filtered dataset in new list to make next line of code easier to write/read\n",
    "            binned_responses=np.mean(filt_data.T.reshape(len(data_neurons[0][:]), 28, 250), axis=2)  \n",
    "                                            #In this case, the sim is 7s, so there are 28 bins each 250ms (28bins*250ms/bin=7000ms=7s)\n",
    "                        #calculating the mean of each 'bin'; the 'reshape' code is reformatting the 1ms-bin data \n",
    "                        #into 250ms-bin data // basically, computing mean across 250 ms window while reformatting\n",
    "                    #I think, axis=2 means that the mean is being computed per 250ms defined bins AND per neuron (in data_neurons)\n",
    "            \n",
    "            #creating lists that are composed only of their stim or pre-stim period\n",
    "            t_baseline = 2 #seconds, narrower time window for baseline calculation (ignoring first 0.5s and last 0.5s in 3s window)\n",
    "            t_stim = 3 #seconds, length-of-time window of stimulus period\n",
    "            baseline_period = np.zeros((len(data_neurons[0][:]), int(t_baseline*4))) #8 = 4bins/s*(2 second long baseline/pre-stim analysis period)\n",
    "            stim_period = np.zeros((len(data_neurons[0][:]), (t_stim*4))) #12 = 4bins/s*(3 second long stimulus period)\n",
    "    \n",
    "            for i in range(len(data_neurons[0][:])):\n",
    "                for j in range(int(t_baseline*4)):\n",
    "                    baseline_period[i][j] = binned_responses[i][j+2] # add 2 to shift the period forward 0.5s to ignore low-activity while model starts up/gets neurons to baseline\n",
    "                for k in range((t_stim*4)):\n",
    "                    stim_period[i][k] = binned_responses[i][k+(int(t_baseline*4)+4-1)] \n",
    "                                                                            # add 4 to shift the period forward 1s to account for entire 3s pre-stim window\n",
    "                                                                            # minus 1 because we're coding in python which starts at 0\n",
    "\n",
    "    \n",
    "            #filling lists that are composed only of their stim or pre-stim period\n",
    "            max_response = np.max(stim_period, axis=1)\n",
    "            min_response = np.min(stim_period, axis=1)\n",
    "            baseline_response = np.mean(baseline_period, axis=1)\n",
    "    \n",
    "            return max_response, min_response, baseline_response\n",
    "                \n",
    "\n",
    "        result = dict(\n",
    "            max_response_ORN=calc_max_min_baseline(data_ORN)[0],\n",
    "            max_response_uPN=calc_max_min_baseline(data_uPN)[0],\n",
    "            max_response_mPN=calc_max_min_baseline(data_mPN)[0],\n",
    "            max_response_Picky=calc_max_min_baseline(data_Picky)[0],\n",
    "            max_response_Broad=calc_max_min_baseline(data_Broad)[0],\n",
    "            max_response_Choosy=calc_max_min_baseline(data_Choosy)[0],\n",
    "            max_response_Ventral=calc_max_min_baseline(data_Ventral)[0],\n",
    "            max_response_Keystone=calc_max_min_baseline(data_Keystone)[0],\n",
    "            \n",
    "            min_response_ORN=calc_max_min_baseline(data_ORN)[1],\n",
    "            min_response_uPN=calc_max_min_baseline(data_uPN)[1],\n",
    "            min_response_mPN=calc_max_min_baseline(data_mPN)[1],\n",
    "            min_response_Picky=calc_max_min_baseline(data_Picky)[1],\n",
    "            min_response_Broad=calc_max_min_baseline(data_Broad)[1],\n",
    "            min_response_Choosy=calc_max_min_baseline(data_Choosy)[1],\n",
    "            min_response_Ventral=calc_max_min_baseline(data_Ventral)[1],\n",
    "            min_response_Keystone=calc_max_min_baseline(data_Keystone)[1],\n",
    "            \n",
    "            baseline_response_ORN=calc_max_min_baseline(data_ORN)[2],\n",
    "            baseline_response_uPN=calc_max_min_baseline(data_uPN)[2],\n",
    "            baseline_response_mPN=calc_max_min_baseline(data_mPN)[2],\n",
    "            baseline_response_Picky=calc_max_min_baseline(data_Picky)[2],\n",
    "            baseline_response_Broad=calc_max_min_baseline(data_Broad)[2],\n",
    "            baseline_response_Choosy=calc_max_min_baseline(data_Choosy)[2],\n",
    "            baseline_response_Ventral=calc_max_min_baseline(data_Ventral)[2],\n",
    "            baseline_response_Keystone=calc_max_min_baseline(data_Keystone)[2]\n",
    "        )\n",
    "                            \n",
    "        \n",
    "        if plt:\n",
    "            legends=[names_ORN, names_uPN, names_mPN, names_Picky,\n",
    "                    names_Broad, names_Choosy, names_Ventral, names_Keystone]\n",
    "            titles=['ORNs '+str(p.hemisphere), 'uPNs '+str(p.hemisphere), 'mPNs '+str(p.hemisphere), 'Pickys '+str(p.hemisphere),\n",
    "                   'Broads '+str(p.hemisphere), 'Choosys '+str(p.hemisphere), 'Ventral '+str(p.hemisphere), 'Keystone '+str(p.hemisphere)]\n",
    "\n",
    "            fig, axs = plt.subplots(8,1, figsize=(30, 80))\n",
    "            fig.suptitle(str(p.hemisphere)+' AL | species = '+str(p.species)+' | odor = '+str(p.odorant)+' | conc = '+str(p.concentration), fontsize = 20, y=0.92)\n",
    "                         # +' | w_OSN_Picky/uPN/mPN = '\n",
    "                         #+str(p.w_ORN_Picky)+'/'+str(p.w_ORN_uPN)+'/'+str(p.w_ORN_mPN)+\n",
    "                         #' | w_Picky_Picky/uPN/mPN = '+str(p.w_Picky_Picky)+'/'+str(p.w_Picky_uPN)+'/'+str(p.w_Picky_mPN)\n",
    "                         #, fontsize = 20, y=0.92)\n",
    "                            \n",
    "            for j, i in enumerate([p_ORN,p_uPN,p_mPN,p_Picky,p_Broad,p_Choosy,p_Ventral,p_Keystone]):\n",
    "                filt = nengo.synapses.Lowpass(0.3)\n",
    "                new_simdata = np.transpose(sim.data[i])\n",
    "                for m, neuron in enumerate(i.target):\n",
    "                    if m>=0 and m<10:\n",
    "                        y_data_list = sim.data[i]\n",
    "                        axs[j].plot(sim.trange(), filt.filtfilt(new_simdata[m]), linewidth=2, linestyle = '-')\n",
    "                    if m>=10 and m<20:\n",
    "                        axs[j].plot(sim.trange(), filt.filtfilt(new_simdata[m]), linewidth=2, linestyle = '--')\n",
    "                    if m>=20 and m<30:\n",
    "                        axs[j].plot(sim.trange(), filt.filtfilt(new_simdata[m]), linewidth=2, linestyle = ':')\n",
    "                axs[j].axvline(x=3, color='gray')\n",
    "                axs[j].axvline(x=6, color='gray')\n",
    "                axs[j].tick_params(axis='y', labelsize= 20)\n",
    "                axs[j].set_xticks([0,3,6,7]) #,30,35,50,55])\n",
    "                axs[j].set_xticklabels(['start','ON','OFF','stop'], fontsize = 20) #,'[-6] ON','[-6] OFF','[-5] ON','[-5] OFF'\n",
    "                axs[j].legend(labels=legends[j], bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0., fontsize = 15)\n",
    "                axs[j].set_title(titles[j], fontsize = 25) \n",
    "                axs[j].set_ylabel('Firing rate (spikes/s)', fontsize = 30)\n",
    "            #plt.savefig('25July2022_LinePlot_allAL_'+str(p.species)+'_'+str(p.hemisphere)+'_'+str(p.odorant)+'_conc'+str(p.concentration)+'.png')\n",
    "            plt.show()\n",
    "            \n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = PickyTrial_AL().run(hemisphere='right', odorant='2-heptanone', species='melanogaster', concentration=-4, plt=True,\n",
    "                        w_ORN_uPN = 0.0005, \n",
    "                        w_ORN_mPN = 0.0010,\n",
    "                        w_ORN_ORN = 0.01,\n",
    "                        w_ORN_Picky = 0.0005,\n",
    "                        w_ORN_Broad = 0.00015,\n",
    "                        w_ORN_Keystone = 0.0006,\n",
    "                        w_ORN_Choosy = 0.0020,\n",
    "                        w_ORN_Ventral = 0.0020,\n",
    "                       background_rate_OR=7.5)\n",
    "                       #, data_dir='TEST_20July2021_Single_uPN-Grid-Tuning_exp2_gridC', data_format='npz') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_10(listboi):\n",
    "    new_listboi = []\n",
    "    for i in listboi:\n",
    "        new_listboi.append(i/10)\n",
    "    return new_listboi\n",
    "\n",
    "conc_r_ga = divide_10(list(range(-80, -59, 1)))                                       #10^ - 8 to -6 \n",
    "conc_r_anisole = divide_10(list(range(-80, -39, 1)))                                  #10^ - 8 to -4 \n",
    "conc_r_2hept = divide_10(list(range(-100, -39, 1)))                                   #10^ - 8 to -4 \n",
    "conc_r_menthol = divide_10(list(range(-80, -39, 1)))                                  #10^ -10 to -4 \n",
    "conc_r_methyl_salicylate = divide_10(list(range(-100, -39, 1)))                       #10^ -10 to -4 \n",
    "conc_r_benzaldehyde = divide_10(list(range(-100, -39, 1)))                            #10^ -10 to -4 \n",
    "conc_r_acetal = divide_10(list(range(-80, -39, 1)))                                   #10^ - 8 to -4 \n",
    "conc_r_methyl_phenyl_sulfide = divide_10(list(range(-100, -39, 1)))                   #10^ -10 to -4 \n",
    "\n",
    "conc_ranges_8odors = [conc_r_ga, conc_r_anisole, conc_r_2hept, conc_r_menthol,\n",
    "                        conc_r_methyl_salicylate, conc_r_benzaldehyde, conc_r_acetal, conc_r_methyl_phenyl_sulfide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, g in enumerate(['melanogaster', 'erecta']):\n",
    "    for m, n in enumerate(['left', 'right']):\n",
    "        for seed in range(3):\n",
    "            for j, i in enumerate(['geranyl acetate', 'anisole', '2-heptanone', 'menthol',\n",
    "                'methyl salicylate', 'benzaldehyde', 'acetal', 'methyl phenyl sulfide']): \n",
    "                for conc in conc_ranges_8odors:\n",
    "                    PickyTrial_AL().run(hemisphere=n, odorant=i, species=g, concentration=conc, plt=False,\n",
    "                                        data_dir='25July2022_V3allAL_'+str(g)+'_'+str(n),\n",
    "                                        data_format='npz', seed=seed, verbose=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
